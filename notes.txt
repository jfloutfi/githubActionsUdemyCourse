workflow automation service by github
CI/CD

continous integration -> integrating new changes to existing code base
continous delivery/deployment

new syntax: 
git branch -> allows you to create branches instead of checkout -b
git swicth to swicth branches
git switch -c -> create and switch

git remote add origin url
origin is a name, this can be written as: git remote add someOnlineRepo url
the term origin is just a name (alias) for a remote repository URL.

git remote set-url https://jfloutfi@github.com/jfloutfi/someRepo.git
setting the remote URL like this tells github that when interacting with this repo, assume user jfloutfi
then: git push origin main -> will ask us for a password. This can then be created in settings -> Developer settings -> Personal access toke
make sure to check "repo"
generate the token and copy it
once use locally as a password, the system will store it for future use
use --set-upstream to connect the local branch with its remote conterpart branch

git remote and git remote get-url origin will show us the alias and the url or the remote repo

Pull requests can be created accross forks
once you fork a repo and you push some changes to another branch,
you can then, from the page of the orignal repo, created a pull request from the branch on your fork to the original repo

GitHub Actions
--------------
We can have multiple workflows
workflows can run un parallel

each workflow can have multiple jobs
jobs can run in parallel
jobs can be conditional, for example only run if the previous job succeeds or fails

each job can have multiple steps
steps are sequential
steps can be conditional


The first line must be: "name"
name: my workflow

on: key reserved to define the event to when to trigger this workflow, workflow_dispatch value make sure we can manually trigger this workflow

jobs: below you define the jobs, yml works with indentations
jobs:
    fist-job: // this is the job name, it is not a reseved keyword
        runs-on: ubuntu-latest => search for these online, you will find the list of available runners in github documentation https://github.com/actions/runner-images
        steps: // below we define the steps, each starting with a "-"
            - name: Print greeting
              run: command to run

Since we are using a github server, we need to get the code from the repo before running things
The github server does not have access to our code automatically
in this case, we need a step with an action
run: => shell commands
uses: (for actions) a custom application that performs a frequent complex repeated task
there are official actions but the github team and one contributed by the comunity
There is an actions marketplace, all actions there are actually free 
Use the "checkout" action to fetch your code
actions/checkout@v5 => version is optional, but it is better to lock it in in case of future breaking changes
the "with" keyword, belongs to the "use" keyword, and can be used to set config options to the action

When it comes the runners, check the github documentation, most runners have preinstalled software
like ubunut-latest already has nodejs installed

in case you get a permission error, you will need to generate a new token from settings -> developer settings
that allows updating workflows

working dir can be set per step:
working-directory: my-folder (in case we want to cd into a certain dir)

or as a default for all steps at job level
runs-on: ubuntu-latest
  defaults:
    run:
      working-directory: my-folder

the default can be specified at workflow level and applies to all jobs

by default, jobs run in parallel
in order to run them sequentially, we need to specify that the 2nd step needs the 1st
the keyword used here is "needs", the value is the 1st job's name
the value can also be an arryay of job names, to make the step wait for multiple jobs to finish 

we can of course have multiple triggers, for example:
on: [push, workflow_dispatch]

Context Objects:
----------------
run: echo "${{ toJSON(github) }}"
we use ${{ ... }} => contains an expression
github context object, there are many others that you can check in the documentation
https://docs.github.com/en/actions/concepts/workflows-and-actions/expressions
https://docs.github.com/en/actions/reference/workflows-and-actions/contexts
context names are reserved keywords

toJSON => function provided by github to transform the object into printable data

Control workflow with types and filters
---------------------------------------
example, no on every push I want to trigger a workflow

each event (push, workflow_dispatch... etc) has activity types
for example:

instead of "on: push", you use yml indented structure style like steps, for example:
on:
  pull_request:
    types:
      - opened
  workflow_dispatch: we have to add the rest of the events like this even if we are not adding any filters to them

defaults:
  run:
    working-directory: 01-Starting-Project


as for filters, an example when pushing tousing branches:
on:
  push:
    branches:
      - main
      - 'dev-*' => this is a regex for branches that start with 'dev-'
      - 'feat/**' => the double '**' allows for further slashes

we can also have negative filters: branches-ignore for example (check docs for this)
another important filter is the "path" filter, it allows triggering workflows based on which files changes

when it comes to pull requests, it has something special
this is related to opening pull request from forked repos:
for example, people can fork a repo, work on the code themselves,
then open a PR to the original repo from that forked repo instead
of working on a branch for example
creating a PR from a forked repo that is targetting the original repo
qualifies for triggering the workflow
however, the item in "actions", shows up with the exclamation mark
that is because in this case, it requires approval to run
this is usefull to protect the original repo's workflow quota (and money) and spam them with workflow runs
Only the 1st PR in this case will require approval
PS: if the person was already added as a collaborator from the repo settings
then their workflow will run even if comming from a fork since you have added them yourself

workflow runs can be canceled or skipped:
-----------------------------------------
on failure, if a job/step fail, it stops the workflow
this can be customized, my making jobs dependend on independant from each other... etc
workflows can also be canceled manually

github actions provide built in ways to skip workflows
this can be done by finishing commit message with certain substrings
for example "blabla blablba [skip ci]", there are strings you can use, check them in the documentation

THESE ARE SPECIFIC TO PULL AND PUSH EVENTS

Workflows that would otherwise be triggered using on: push or on: pull_request won't be triggered if you add any of the following strings to the commit message in a push, or the HEAD commit of a pull request:
[skip ci]
[ci skip]
[no ci]
[skip actions]
[actions skip]

job artifcats and outputs
-------------------------
This the ourput generated by a job
we can download them manually
we can download them automatically and use them in other jobs

these can also be log files, but mostly, it is stuff that we wanna use in other jobs

NOTE: when the workflow ends, the runner machine is shutdown and its data lost

- name: upload artificat
  uses: actions/upload-artificat@v3
  with:
    name: dist-files => we can name this anything we want
    path: we can have 1 or multiple paths, we use the pipe | when adding multiple paths

Also, the "!" can be used to exlude files

the workdir is alwasy our repo, or the one we specify using: "working-directory: starting-project-01"

IMPORTANT 
---------
when the base dir is not the working dir, you will need to checkout in every job
each job is a new canavs and without checking out, the repo will not be there
OR OR OR, the work dir can be reset at job or set level as such
=> since you set defaults.run.working-directory at the workflow level, every job inherits it. To make one job run from the repo root, just override the default for that job and point it back to . (or ${{ github.workspace }}).

# Override the workflow default just for this job:
defaults:
  run:
    working-directory: .  # or: ${{ github.workspace }}

- name: Run from repo root only here
    run: make package
    working-directory: .               # overrides just this step

Also, upload-artifact will look for files and folders in the base directory,
so you will have to include the workdir in the path:
"./starting-project-01-02/dist" instead of "./dist"

- name: upload artificat
  uses: actions/upload-artifact@v4
  with:
    name: dist-files => it will be uploaded as .zip file
    # the output of "run build" in stored in the ./dist folder
    # based the build command create by the user
    path: |
      ./starting-project-01-02/dist
      ./starting-project-01-02/package.json

As for downloading the built artificate:
- name: get build artifacts
  uses: actions/download-artifact@v4
  with:
    name: dist-files => sepcify the name of the artificat

the artificat will be unzip automatically
the files will be found in the base directory, similarly to upload

output values in Github actions are different from artificats. For example:
"outputs" is added before teach of the steps are defined as part of "steps" config fields

outputs:
  script-file: ${{ steps.publish_id.outputs.script-file }} # steps is a special context variable, we can access step related data using it, the best way would be to give that step an "id". Referencing the output here set this to be the output of the overall job. "script-file:" is not a reserved keyword, it is up to us to name it. We can also add multiple output
steps:
  - name: Get code
    uses: actions/checkout@v4
  - name: Install dependencies
    run: npm ci
  - name: Build website
    run: npm run build
  - name: publish js file name
    id: publish_id # the step id
    run: find dist/assets/*.js -type f -execdir echo 'script-file={}' >> $GITHUB_OUTPUT ';' # {} special place holder, will hold the name of the .js files. We stream the output ">>" to the special env variable variable: $GITHUB_OUTPUT


run: echo "${{ needs.build.outputs.script-file }}"
we could have use the jobs context variable for this, but needs contains
the data of the jobs that have been defined as a dependency for this current job

IMPORTANT: Caching dependencies
-------------------------------
every job runs on its own runner/machine, but
we can cache dependencies accross jobs and Workflows
which help reduce the total run time

- name: cache dependencies
  uses: actions/cache@v4
  with:
    path: ~/.npm # npm builds a cache and other such tools build a cache that they use when deps are being re-installed, in this case, we want to reuse this across jobs since jobs use different machines
    key: deps-node-modules-${{ hashFiles('**/package-lock.json') }} # used to get the cached data
    # hashFiles() is a function that produces a unique has based on a file we provide. When the file content changes, the hash changes
    # for node projects, one of the best files to use is the .lock file, as long as the deps do not change, the file will remain the same
    # for cache keys, it is better to use dynamic names as this helps when it comes to needing to discard this cache

the cache action will also look at the foder after the jobe ends
and if there are changes, the cached data will get updated

Github provides very good offcial examples for many languages

NOTE: the cache uses 1 central cache across jobs and Workflows

in order to use the cache in a another step, you include the same step with the cache action, path and key

Environment Variables
---------------------
They can be defind at workflow or job level (scope)
IMPORTANT: storing passwords ad user names in clear text in workflow file is not IDEAL
in fact, it is a security risk
When we want to use an env variable, in the case of a run instruction (bash with linux), we simply use "$VAR_NAME"
we can also switch the "shell" by adding this keyword to the step

we can also use the "env" context object to access these Variables
for example, ${{ env.VAR_NAME }}

github provides some default env variables, they can be found here:
https://docs.github.com/en/actions/how-tos/write-workflows/choose-what-workflows-do/use-variables#default-environment-variables

Secrets
-------
Go to:
your repo -> settings -> Secrets and variables -> Actions
you will be able to set your sercrets there. Once the secret is set, is can not be viewed anymore
Also, repo variables can be added there.
-> either at repo level, or per environment (these envs can be also create there in order to group and organise secrets and vars)

PS: the secret can be updated (set new value), but can not be seen

in order to use these secrts, with the "secrets" context object
${{ secrets.VAR_NAME }}

even if you try to print such a value, or read it, store it in an env variable then try to print it
github will recognize this and hide it

Environments
------------
these envs are configure from the repo settings and referenced in workflows as such:
per step, you define the "environment" you are using
and you use "secrets" and "vars" to access these secrets and env variables

test-3:
  environment: testing
  runs-on: ubuntu-latest
  steps:
    - name: test vars and secrets
      run: |
        echo "${{ secrets.MY_ENV_SEC }}"
        echo "${{ vars.MY_ENV_VAR }}"
test-4:
  environment: prod
  runs-on: ubuntu-latest
  steps:
    - name: test vars and secrets
      run: |
        echo "${{ secrets.MY_ENV_SEC }}"
        echo "${{ vars.MY_ENV_VAR }}"

Here we can also add some protections (settings on github):
for example, we can sepcify that a workflow requires a reviewrs approval to get executed
these rules can also be limited to certain branches for example, this is different from the "branches" key set in the workflow files, this concerns these protection rules

Conditional Execution
---------------------
can be added at job or step level
we can also continue even if there is an error
expressions can be used to add custom conditions

for example, in a step, we run some tests
if they all pass, then we might not be interested in
uploading the test report... but if it fails, that report can be uploaded for further inspection

in github action, if a step fails, then the entire job to which that step belongs to
is canceled BUT we might be interested in running the next steps anyway

also, if a job fails, the jobs that depend on it will be canceled as well

# for "if", we can omit the use of ${{}} as for this key, the value is typically and expression
if: steps.run-tests.outcome
.outcome: before continue-on-error is applied
vs
.conclusion: after continue-on-error is applied

the results of the 2 above are strings that would need to be compared using '==' for example

# for "if", we can omit the use of ${{}} as for this key, the value is typically and expression
# this as is will still not execute, we need 1 more function
# if: steps.run-tests.outcome == 'failure'
if: failure() && steps.run-tests.outcome == 'failure'

we have 4 of these functions:
- failure() => returns true if any of the previous steps fails
- success() => returns true if none of the previous steps fails
- always() => returns true always even when canceled
- canceled() => returns true if a "workflow" has has been canceled

"if" and these 4 functions can be used a JOB level
For example, adding the bellow as a final job
as is, it will run in parallel at the start and it will not behave as we expect it to
we need the "needs" keyword
report:
  runs-on: ubuntu-latest
  if: failure()
  run: |
    echo something when wrong
    echo "${{ toJSON(github) }}"

For example, we can store the node-modules folder instead of the .npm one
this folder already has the dependencies installed vs .npm containing the binaries
in this case, when Referencing the cache, we want to check if the we have a cache hit,
else we need to install the modules.
The "cache" itself has its own outout, this can be found in its documentation: https://github.com/actions/cache
it has an ouput variable called "cache-hit" that gets set to 'true' or 'false'
If want to use it with a if statement, we can use it as such:
if: steps.cache_step_id.outpus.cache-hits == 'true' or != 'true'
cache_step_id => this you specify use "id" in the step when you handle cache
i.e if condition can be used for other things and not just fail/success and similar statuses

continue-on-error:
------------------
- name: Test code
  id: run-tests # set the id to whatever you want
  continue-on-error: true # we can gibe this an expression as well instead of hardcoding "true"
  run: npm run test
- name: Upload test report
  # for "if", we can omit the use of ${{}} as for this key, the value is typically and expression
  # this as is will still not execute, we need 1 more function
  # if: steps.run-tests.outcome == 'failure'
  # if: failure() && steps.run-tests.outcome == 'failure'
  # here we can use another method: "continue-on-error"
  # this is set on the step before this so that the execution contines even if the step fails